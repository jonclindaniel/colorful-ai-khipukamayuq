{"cells":[{"cell_type":"markdown","metadata":{"id":"6HbZfxtcWWNz"},"source":["# Training an AI Khipukamayuq\n","\n","## Data Preprocessing\n","\n","In order to train an AI Khipukamayuq to parse Inka khipu cord colors, we must first collect cord color data from the Open Khipu Repository ([OKR, v2.0.0](https://zenodo.org/badge/latestdoi/296378423)) that we can use to train the model. Once we have the data, we will also need to preprocess the data to coerce it into a form we can train our model with:"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_UscKy7-oDCR"},"outputs":[],"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","import subprocess\n","import pandas as pd\n","import sqlite3\n","\n","# download OKR v2.0.0 and select KCCS (Brezine) color codes\n","# ordered by khipu and cord position\n","try:\n","    subprocess.Popen(['git', \n","                      'clone', \n","                      'https://github.com/khipulab/open-khipu-repository.git',\n","                      '-b', 'v2.0.0', '--single-branch',\n","                      '--quiet'])\n","except Exception as e:\n","    print(e)\n","\n","conn = sqlite3.connect('open-khipu-repository/khipu.db')\n","\n","query = \\\n","'''\n","SELECT\n","    okr_num,\n","    cord.khipu_id,\n","    cluster_id,\n","    cord_id,\n","    cord_ordinal,\n","    cluster_ordinal,\n","    /* Get clean colors and concatenate colors of segmented cords */\n","    (SELECT brezine_color\n","      FROM\n","          (SELECT\n","              GROUP_CONCAT(REPLACE(TRIM(\n","              c1.color || c1.intensity\n","                || case when color.operator_1 <> ''\n","                then '' || color.operator_1 else '' END\n","                || case when color.color_cd_2 <> ''\n","                then '' || c2.color || c2.intensity else '' END\n","                || case when color.operator_2 <> ''\n","                then '' || color.operator_2 else '' END\n","                || case when color.color_cd_3 <> ''\n","                then '' || c3.color || c3.intensity else '' END\n","                || case when color.operator_3 <> ''\n","                then '' || color.operator_3 else '' END\n","                || case when color.color_cd_4 <> ''\n","                then '' || c4.color || c4.intensity else '' END\n","                || case when color.operator_4 <> ''\n","                then '' || color.operator_4 else '' END\n","                || case when color.color_cd_5 <> ''\n","                then '' || c5.color || c5.intensity else '' END\n","                || case when color.operator_5 <> ''\n","                then '' || color.operator_5 else '' END,\n","                '*:- '), ' ', ''), '/') AS brezine_color,\n","            cord_id\n","          FROM\n","              ascher_cord_color AS color\n","          /*\n","          Find corresponding colors/intensities for Ascher color codes\n","          using Brezine KCCS lookup table in db.\n","          Note that some records also have extraneous chars to clean\n","          */\n","          LEFT JOIN ascher_color_dc AS c1\n","              ON REPLACE(TRIM(color.color_cd_1, '*:- '), ' ', '') = \\\n","                REPLACE(TRIM(c1.as_color_cd, '*:- '), ' ', '')\n","          LEFT JOIN ascher_color_dc AS c2\n","              ON REPLACE(TRIM(color.color_cd_2, '*:- '), ' ', '') = \\\n","                REPLACE(TRIM(c2.as_color_cd, '*:- '), ' ', '')\n","          LEFT JOIN ascher_color_dc AS c3\n","              ON REPLACE(TRIM(color.color_cd_3, '*:- '), ' ', '') = \\\n","                REPLACE(TRIM(c3.as_color_cd, '*:- '), ' ', '')\n","          LEFT JOIN ascher_color_dc AS c4\n","              ON REPLACE(TRIM(color.color_cd_4, '*:- '), ' ', '') = \\\n","                REPLACE(TRIM(c4.as_color_cd, '*:- '), ' ', '')\n","          LEFT JOIN ascher_color_dc AS c5\n","              ON REPLACE(TRIM(color.color_cd_5, '*:- '), ' ', '') = \\\n","                REPLACE(TRIM(c5.as_color_cd, '*:- '), ' ', '')\n","          GROUP BY\n","              cord_id\n","          ORDER BY\n","              color_range\n","\n","          )\n","      WHERE\n","          cord_id = cord.cord_id\n","      ) as color\n","FROM\n","    cord\n","JOIN\n","    khipu_main ON cord.khipu_id = khipu_main.khipu_id\n","WHERE\n","    /*\n","    First order cords -- top cords indicated with negative in deprecated\n","    coding scheme, pendant cords with positive\n","    */\n","    (cord_level = 1 OR cord_level = -(1))\n","ORDER BY\n","    okr_num,\n","    cord_ordinal\n","'''\n","\n","khipu_df = pd.read_sql_query(query, conn)\n","\n","# label khipus w/o cord groups as their OKR num, so that they have separate cord group numbers\n","khipus_wo_cg = (khipu_df.CLUSTER_ID == 0) & (khipu_df.CLUSTER_ORDINAL == 0)\n","khipu_df.loc[khipus_wo_cg,\n","             'CLUSTER_ID'] = khipu_df.loc[khipus_wo_cg]['OKR_NUM']\n","\n","# drop (7) cords that are missing cluster ID, but have non-zero cluster ordinal\n","khipu_df = khipu_df[khipu_df.CLUSTER_ID != 0]\n","khipu_df.loc[:, 'CLUSTER_ID'] = khipu_df.loc[:, 'CLUSTER_ID'].astype(str)\n","\n","\n","# Drop khipus that have no recorded colors on them\n","# (but keep cords without recorded colors if other portions of the khipu\n","# are recorded)\n","khipu_ids_to_check = khipu_df.loc[khipu_df.color.isna()] \\\n","                             .groupby('KHIPU_ID') \\\n","                             .count() \\\n","                             .sort_values('color', ascending=False) \\\n","                             .color \\\n","                             .index\n","\n","all_cord_colors_missing = []\n","for id in khipu_ids_to_check:\n","    if len(khipu_df[(khipu_df.KHIPU_ID == id) & (khipu_df.color.isna())]) \\\n","        == (len(khipu_df[(khipu_df.KHIPU_ID == id)])):\n","        all_cord_colors_missing.append(id)\n","\n","khipu_df = khipu_df.loc[~khipu_df.KHIPU_ID.isin(all_cord_colors_missing)] \\\n","                   .rename(columns={'OKR_NUM': 'okr_num',\n","                                    'CLUSTER_ID': 'cluster_id'})\n","khipu_cg_map = khipu_df[['okr_num', 'cluster_id']].drop_duplicates()\n","\n","# Drop remaining cords without colors recorded for training tokenizer\n","cg_df_tok_trn = khipu_df.loc[khipu_df.color.notna(),\n","                             ['cluster_id', 'color']] \\\n","                        .groupby('cluster_id') \\\n","                        .color.apply(' '.join)\n","\n","cg_df_tok_trn = pd.merge(left=cg_df_tok_trn,\n","                         right=khipu_cg_map,\n","                         on='cluster_id')\n","\n","# Fill NA values as [UNK] for training model\n","khipu_df.loc[khipu_df.color.isna(), 'color'] = '[UNK]'\n","cg_df = khipu_df.loc[:, ['cluster_id', 'color']] \\\n","                .groupby('cluster_id') \\\n","                .color.apply(' '.join)\n","\n","cg_df = pd.merge(left=cg_df,\n","                 right=khipu_cg_map,\n","                 on='cluster_id')"]},{"cell_type":"markdown","metadata":{"id":"JzAvKyTBm4Zg"},"source":["We then have data that looks like so:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1690298408112,"user":{"displayName":"Jon Clindaniel","userId":"17358510137887145828"},"user_tz":300},"id":"xt9OdkvTBk1n","outputId":"b4e739ce-2743-4832-d5f3-028df4192bd1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cluster_id</th>\n","      <th>color</th>\n","      <th>okr_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000000</td>\n","      <td>B2 B2 B2</td>\n","      <td>KH0255</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000001</td>\n","      <td>B3 B2 B4 B3</td>\n","      <td>KH0255</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000002</td>\n","      <td>B3 B4:A1 B3:B4 A1 H2</td>\n","      <td>KH0255</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000003</td>\n","      <td>H2</td>\n","      <td>KH0255</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000009</td>\n","      <td>A1 A1 A1 A1</td>\n","      <td>KH0244</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  cluster_id                 color okr_num\n","0    1000000              B2 B2 B2  KH0255\n","1    1000001           B3 B2 B4 B3  KH0255\n","2    1000002  B3 B4:A1 B3:B4 A1 H2  KH0255\n","3    1000003                    H2  KH0255\n","4    1000009           A1 A1 A1 A1  KH0244"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["cg_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Note that this dataset includes approximately 50k color recordings:"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of (first order) cord groups:  6592 \n","Total number of (first order) cords with recorded color:  37645 \n","Total number of (first order) recordings (including color combo cords):  48681\n"]}],"source":["print(\"Total number of (first order) cord groups: \", \n","      cg_df.cluster_id.count(),\n","      \"\\nTotal number of (first order) cords with recorded color: \",\n","      khipu_df.loc[khipu_df.color != '[UNK]'].color.count(),\n","      \"\\nTotal number of (first order) recordings (including color combo cords): \",\n","      khipu_df.loc[khipu_df.color != '[UNK]'] \\\n","                      .color.str.extractall('([A-Z]{1}[0-9]{1})') \\\n","                      .count()[0]\n",")"]},{"cell_type":"markdown","metadata":{"id":"6_T3FbeWj4T-"},"source":["## Deep Learning Workflow\n","\n","The data is now in a form that we can use to train our model. Here, we're primarily interested in interpretive tasks, so we will train a BERT model (an encoder model that will allow us to encode a contextual embedding for each cord in the OKR based on its color and the colors of cords surrounding it in a cord group). Let's first load in some packages and functions that we will use:"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16644,"status":"ok","timestamp":1711896519147,"user":{"displayName":"Jon Clindaniel","userId":"17358510137887145828"},"user_tz":300},"id":"Q8932VuMYxQw"},"outputs":[],"source":["from datasets import load_dataset, load_from_disk, Dataset\n","from transformers import TrainingArguments, Trainer, BertTokenizerFast, BertForMaskedLM, BertConfig, DataCollatorForLanguageModeling\n","from tokenizers import BertWordPieceTokenizer\n","import torch\n","import pandas as pd\n","import os\n","import json\n","from itertools import chain\n","\n","file_path = \"./data\"\n","model_path = \"./pretrained-bert\"\n","SEED = 7\n","\n","# define two functions from documentation for send dataset to file\n","# and grouping texts together for training\n","def dataset_to_text(dataset, output_filename=\"data.txt\"):\n","  '''\n","  Utility function to save dataset text to disk,\n","  useful for using the texts to train the tokenizer\n","  (as the tokenizer accepts files). From HuggingFace documentation.\n","  '''\n","  os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n","  with open(output_filename, \"w\") as f:\n","    for t in dataset[\"color\"]:\n","      print(t, file=f)\n","\n","def group_texts(examples):\n","    '''\n","    Main data processing function that will concatenate all texts from our\n","    dataset and generate chunks of max_seq_length. From example code:\n","    https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","\n","    Note that, when mapping this function using `map` with `batched=True`,\n","    map processes 1,000 texts together, so group_texts throws away a remainder\n","    for each of those groups of 1,000 texts (can adjust batch_size as needed).\n","    '''\n","    # Concatenate all texts.\n","    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n","    # customize this part to your needs.\n","    if total_length >= max_length:\n","        total_length = (total_length // max_length) * max_length\n","    # Split by chunks of max_length\n","    result = {\n","        k: [t[i : i + max_length] for i in range(0, total_length, max_length)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"2SIshhv2Gtc4"},"source":["### Read Data for Training Tokenizer and BERT\n","\n","Then, let's load in our `pandas` DataFrames as `Dataset` objects. We can also split up our data into training and testing data."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FHIRjVzEIwBb"},"outputs":[],"source":["# Process dataset and write to file for training tokenizer\n","dataset_tok_trn = Dataset.from_pandas(cg_df_tok_trn[['color']] \\\n","                         .reset_index(drop=True))\n","dataset_to_text(dataset_tok_trn, f\"{file_path}/tok_trn.txt\")\n","\n","# Read in full dataset for training BERT and split into train/test data\n","dataset = Dataset.from_pandas(cg_df.reset_index(drop=True))\n","\n","d = dataset.train_test_split(test_size=0.2, seed=SEED)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1690298437105,"user":{"displayName":"Jon Clindaniel","userId":"17358510137887145828"},"user_tz":300},"id":"MKwLh0SCGbx7","outputId":"419974c0-0d24-4dec-9d62-c0ea77bbf077"},"outputs":[{"data":{"text/plain":["{'cluster_id': ['1005554', '1003449', '1019734', '1013530', '1019117'],\n"," 'color': ['B3 B2:B3:A1 B3:A1 B3:A1',\n","  'A1*Z5/A1/A1*Z5/A1',\n","  'A1 B3 B4:B2 B4:A1 B2 H3 B2',\n","  'B3 B3 B3 B3',\n","  '[UNK]'],\n"," 'okr_num': ['KH0014', 'KH0082', 'KH0081', 'KH0079', 'KH0502']}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["d['train'][:5] # see what the data looks like"]},{"cell_type":"markdown","metadata":{"id":"4Na6jTvOgGkS"},"source":["### Train Tokenizer\n","\n","We then need to train a tokenizer to learn distinct cord colors as well as standard cord color combination operators and special tokens that can be recognized by the BERT model -- i.e. separations between cord groups, the start of cord group sequences, masked cords, etc. Note that a small subset of color combination cords (19) are recorded without color combination operators in the OKR. In the absence of additional information about how they were formed, these colors are denoted with their own unique (multi-color) tokens in the tokenizer's vocabulary.\n","\n","We can train our tokenizer like so:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"i8ntiem8Y0E9"},"outputs":[],"source":["# BERT special tokens\n","special_tokens = [\n","  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n","]\n","\n","# maximum sequence length\n","max_length = 512\n","\n","# initialize the tokenizer\n","tokenizer = BertWordPieceTokenizer()\n","\n","# train the tokenizer\n","tokenizer.train(files=[f\"{file_path}/tok_trn.txt\"],\n","                special_tokens=special_tokens)\n","\n","# make a directory if not already there\n","if not os.path.isdir(model_path):\n","  os.mkdir(model_path)\n","\n","# save the tokenizer\n","tokenizer.save_model(model_path)\n","\n","# save tokenizer config to file\n","with open(os.path.join(model_path, \"config.json\"), \"w\") as f:\n","  tokenizer_cfg = {\n","      \"do_lower_case\": True,\n","      \"unk_token\": \"[UNK]\",\n","      \"sep_token\": \"[SEP]\",\n","      \"pad_token\": \"[PAD]\",\n","      \"cls_token\": \"[CLS]\",\n","      \"mask_token\": \"[MASK]\",\n","      \"model_max_length\": max_length,\n","      \"max_len\": max_length,\n","  }\n","  json.dump(tokenizer_cfg, f)"]},{"cell_type":"markdown","metadata":{"id":"VVKp9fJFgAvl"},"source":["### Tokenize Train/Test Data\n","\n","Now we can load our tokenizer and use it to tokenize our test and training data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321,"referenced_widgets":["0e4a243c0ffb4d6a8e0f2345a4ef2db1","ee2e9be1159540579465684704237e97","986dd0a366e34022a1aeea06a61fcf6b","52a4e5f9973f418ba3f669b2ec7a33cf","087e2dda94ae48b5940fe1046788b93e","80c25465aeae42b19c33483bcdd90831","117ab056d43e45aa839b38e4453274ca","3313a12496d94fdaa8ce49c7d791edc8","f0fe3eab405a45c89c60396b12fff84e","dceec7de2d4241099e444c7d327dc834","942a10847a2841d89e4ba0ca03ce3ee5","e331243aab7c45d990873375bd2becd2","78739a07dd6e4f45898150c283a9a747","928d4bdb9e474af6aede0b11e6ce8d24","610d9bd12012465eaea85ed9b410753d","227761f31b084d14bb6def78d797efd4","6c7dcd616828487a9ab4611e26389397","e0f5e6c649a3439a83c6b334958c9518","c7e07967d0244e229862ed986c9b74f9","e5a89aaf36b54590a1b57957eaf7732e","8a9775858d734fb79294c701d9230b44","17fb4b7c57324b09acbce35c5a735715","5f3a6461685445bcbccb240ba3c0fab6","6c2402cb5cdb40d0a2e3ed97194462fd","aa37590628ec4bf9884cb1c1b451ea9d","09a1ef5b504f48c1a9764a5976e697d3","9a9cf7a1fe2742aa892c04aa352b28af","15ca1b1cdcd24efcae051bebebe3b2ee","e0f9c2ec412049f2a5acd275dcc05def","00d3c09880db452fb741c24b77305b77","31db8f0749284e9c8f5745352474fc2a","4e808be0cfa44d249c9d1252f9a33a85","0d4c9a9cabe8452e9f34439fc01db253","682f0d7060a449dfbbee0705ff5e23bd","54fe9f1c84874a3391af0ff86277b2cf","f514f09c710041d49c47593f7075bb9a","2f870e8cafe6498a86d89b99d3af956b","2c8310205c6041b1b2ea9dad30e5d62f","8865bbf1e492471381609b48b756a2fb","21715587340b4c5fbb8b5cb2b9d3d664","52ee20b10eca4cfc8c837fdf22860b1e","784aa071c99e4172a458ec1df4938721","a35e7a662d364fa1abacc84bbe10a0cf","88bc9b8b142f4343858e4087965aed63","46d100c32f06475babf5293ca3b22c6b","efeab024444b4ca3aeab5b61d46cd83c","096bac360d254ef19e0dd7b25dd23e48","6307a900f2a24e8eb037cfa76b9854e9","15f1dcce6b58451fa2d80931e4b49a73","422f1045b6f24a92b7ba54a359b1e73c","be110631983d4b29a0d41d6b307e7871","0ecff2dd44dc474d8b415ce4edf02de6","d71f0e5d89a74949a396af67f4dd7b9d","b6c10aecea3c4a2a90760b3c8262727b","037255961faa4b3e9f7fc93aea3241d9","bdf17793746049e58f4baeac1289f83e","e9f84369cfd243efb2b891ce78878e37","bd0c148658eb46e9b7bf5b2e3a727cd6","2e12cb0bfd3441ffad6a7da14df21393","40e2a77a2dc541808f6d2af22ff66ab7","34780ec893524d7ab805fe3dadc6b811","e4dde512a0ab40f7872c088d05398924","e1c84d91af4b4aa0bff4950c7df0e6a9","b6fb78eb656a4969955496ab74a38459","ba8e97e454384db4ba9a7c06073ca5c4","f87bf027260d4cd2a53f5f49fbecf741"]},"executionInfo":{"elapsed":6492,"status":"ok","timestamp":1690298446427,"user":{"displayName":"Jon Clindaniel","userId":"17358510137887145828"},"user_tz":300},"id":"KFvO3r-Ve8WD","outputId":"8445d60b-e2bb-4e74-f4dc-ae9172a85b29"},"outputs":[],"source":["# when the tokenizer is trained and configured, load it as BertTokenizerFast\n","tokenizer = BertTokenizerFast.from_pretrained(model_path)\n","\n","# Mapping function to tokenize with truncation + padding to match max length\n","encode = lambda x: tokenizer(x[\"color\"],\n","                             return_special_tokens_mask=True,\n","                             truncation=True,\n","                             max_length=max_length)\n","\n","# tokenize train and test data\n","train_dataset = d[\"train\"].map(encode, batched=True)\n","\n","# tokenizing the testing dataset\n","test_dataset = d[\"test\"].map(encode, batched=True)\n","\n","# Concatenate color groupings together to max length accepted by model per line\n","train_dataset = train_dataset.map(group_texts, batched=True,\n","                              desc=f\"Grouping texts in chunks of {max_length}\")\n","test_dataset = test_dataset.map(group_texts, batched=True,\n","                              desc=f\"Grouping texts in chunks of {max_length}\")\n","\n","# convert from lists to torch tensors\n","train_dataset.set_format(type=\"torch\", columns=[\"input_ids\",\n","                                                \"attention_mask\",\n","                                                \"special_tokens_mask\"])\n","test_dataset.set_format(type=\"torch\", columns=[\"input_ids\",\n","                                               \"attention_mask\",\n","                                               \"special_tokens_mask\"])\n","\n","# save tokenized training and test data for training BERT model\n","train_dataset.save_to_disk(f\"{file_path}/train\")\n","test_dataset.save_to_disk(f\"{file_path}/test\")"]},{"cell_type":"markdown","metadata":{"id":"VnWY-ETawC1h"},"source":["## Training the Model\n","\n","Finally, we can train our BERT model using the tokenized train and test data we just produced (note that I ran the script `./hp_search.py` to perform a hyperparameter search for the optimal learning rate -- incorporated below). The code in `hp_search.py` and below is best run on a GPU (this code was tested on a NVIDIA T4 GPU in the Google Cloud, as well as on a NVIDIA RTX 4060 laptop GPU). The pretrained model has been saved to this repository and can also be loaded for use in `analysis.ipynb` without running this code."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":393265,"status":"ok","timestamp":1711900538357,"user":{"displayName":"Jon Clindaniel","userId":"17358510137887145828"},"user_tz":300},"id":"38nQh9SSvFHd","outputId":"013ed3ac-d5a0-4446-b07b-6350c48dcbc2"},"outputs":[{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n","The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","c:\\Users\\jclindaniel\\AppData\\Local\\anaconda3\\envs\\bearc\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 68\n","  Num Epochs = 24\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 400\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc72ae4a5fba46bbb5b9aaabec8ae69a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/400 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 6.3689, 'learning_rate': 4.875e-05, 'epoch': 0.59}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac8f30af460a4b6e95cffe7648c84cc8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 4.754756927490234, 'eval_runtime': 0.5475, 'eval_samples_per_second': 31.05, 'eval_steps_per_second': 31.05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 4.5204, 'learning_rate': 4.75e-05, 'epoch': 1.18}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acb0aba562b947b3892abec244d1cd19","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 4.154697418212891, 'eval_runtime': 0.5379, 'eval_samples_per_second': 31.604, 'eval_steps_per_second': 31.604, 'epoch': 1.18}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.9122, 'learning_rate': 4.6250000000000006e-05, 'epoch': 1.76}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a107b2bb9b0408280eb37b6a95e1dc0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 3.517988681793213, 'eval_runtime': 0.5395, 'eval_samples_per_second': 31.513, 'eval_steps_per_second': 31.513, 'epoch': 1.76}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.4944, 'learning_rate': 4.5e-05, 'epoch': 2.35}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25efe5373a6a47fd9818b3f6d581efb2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 3.135415554046631, 'eval_runtime': 0.5664, 'eval_samples_per_second': 30.013, 'eval_steps_per_second': 30.013, 'epoch': 2.35}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.1173, 'learning_rate': 4.375e-05, 'epoch': 2.94}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9004ee0390684abcbbfd1d1e500326fd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 3.0580060482025146, 'eval_runtime': 0.5433, 'eval_samples_per_second': 31.288, 'eval_steps_per_second': 31.288, 'epoch': 2.94}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.075, 'learning_rate': 4.25e-05, 'epoch': 3.53}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c91a7ff0fbb4a04b5eabf9d9204ec5e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.769441604614258, 'eval_runtime': 0.5513, 'eval_samples_per_second': 30.837, 'eval_steps_per_second': 30.837, 'epoch': 3.53}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.698, 'learning_rate': 4.125e-05, 'epoch': 4.12}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dadf6f04495e43ff8c04902cdfb505a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.4883182048797607, 'eval_runtime': 0.6298, 'eval_samples_per_second': 26.993, 'eval_steps_per_second': 26.993, 'epoch': 4.12}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.5274, 'learning_rate': 4e-05, 'epoch': 4.71}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b3500b8d56c4b319775ec8fae787c3d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.4609286785125732, 'eval_runtime': 0.676, 'eval_samples_per_second': 25.148, 'eval_steps_per_second': 25.148, 'epoch': 4.71}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.3652, 'learning_rate': 3.875e-05, 'epoch': 5.29}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d714300f27644b319591a5279df7a86e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.1892290115356445, 'eval_runtime': 1.2918, 'eval_samples_per_second': 13.16, 'eval_steps_per_second': 13.16, 'epoch': 5.29}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.3224, 'learning_rate': 3.7500000000000003e-05, 'epoch': 5.88}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19be4ce45a344b00992ed105f0f42ed7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./pretrained-bert\\checkpoint-100\n","Configuration saved in ./pretrained-bert\\checkpoint-100\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.2673215866088867, 'eval_runtime': 0.7937, 'eval_samples_per_second': 21.418, 'eval_steps_per_second': 21.418, 'epoch': 5.88}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./pretrained-bert\\checkpoint-100\\pytorch_model.bin\n","Deleting older checkpoint [pretrained-bert\\checkpoint-400-use] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.2901, 'learning_rate': 3.625e-05, 'epoch': 6.47}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90e714fd501247959f42de1150eeb650","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.1622025966644287, 'eval_runtime': 0.8513, 'eval_samples_per_second': 19.968, 'eval_steps_per_second': 19.968, 'epoch': 6.47}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.161, 'learning_rate': 3.5e-05, 'epoch': 7.06}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1aaffc46716438b9e7dffe2562fd862","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.13019061088562, 'eval_runtime': 0.7943, 'eval_samples_per_second': 21.403, 'eval_steps_per_second': 21.403, 'epoch': 7.06}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.1634, 'learning_rate': 3.375000000000001e-05, 'epoch': 7.65}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5315dd4b22e48eea6d59cbd217badfd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0932505130767822, 'eval_runtime': 2.1319, 'eval_samples_per_second': 7.974, 'eval_steps_per_second': 7.974, 'epoch': 7.65}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0706, 'learning_rate': 3.2500000000000004e-05, 'epoch': 8.24}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c48ae5a46df4bcf9f99f842fdc11c60","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.043602466583252, 'eval_runtime': 1.89, 'eval_samples_per_second': 8.995, 'eval_steps_per_second': 8.995, 'epoch': 8.24}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.1683, 'learning_rate': 3.125e-05, 'epoch': 8.82}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e6bdd4d61f44e68a8073a90b36f302b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.057720422744751, 'eval_runtime': 2.2585, 'eval_samples_per_second': 7.527, 'eval_steps_per_second': 7.527, 'epoch': 8.82}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0331, 'learning_rate': 3e-05, 'epoch': 9.41}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"301552b8146846b68a2c80d08e30e262","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0538573265075684, 'eval_runtime': 2.3233, 'eval_samples_per_second': 7.317, 'eval_steps_per_second': 7.317, 'epoch': 9.41}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0104, 'learning_rate': 2.8749999999999997e-05, 'epoch': 10.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"212eaf8826ae40628fbc73f9f67e5c58","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0223894119262695, 'eval_runtime': 1.2372, 'eval_samples_per_second': 13.741, 'eval_steps_per_second': 13.741, 'epoch': 10.0}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0394, 'learning_rate': 2.7500000000000004e-05, 'epoch': 10.59}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"779ab3411ebf4a03912288c1222a8b36","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0721893310546875, 'eval_runtime': 1.0368, 'eval_samples_per_second': 16.397, 'eval_steps_per_second': 16.397, 'epoch': 10.59}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0728, 'learning_rate': 2.625e-05, 'epoch': 11.18}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"212af09176724581b22589661a13597b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.020432949066162, 'eval_runtime': 1.6198, 'eval_samples_per_second': 10.495, 'eval_steps_per_second': 10.495, 'epoch': 11.18}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0742, 'learning_rate': 2.5e-05, 'epoch': 11.76}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27bf27f01965429b9c243aea99a91c85","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./pretrained-bert\\checkpoint-200\n","Configuration saved in ./pretrained-bert\\checkpoint-200\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.032832384109497, 'eval_runtime': 1.7962, 'eval_samples_per_second': 9.464, 'eval_steps_per_second': 9.464, 'epoch': 11.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./pretrained-bert\\checkpoint-200\\pytorch_model.bin\n","Deleting older checkpoint [pretrained-bert\\checkpoint-100] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0086, 'learning_rate': 2.375e-05, 'epoch': 12.35}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc50ac6da4344e63a9ece19b62babe9c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9972538948059082, 'eval_runtime': 3.1788, 'eval_samples_per_second': 5.348, 'eval_steps_per_second': 5.348, 'epoch': 12.35}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9813, 'learning_rate': 2.25e-05, 'epoch': 12.94}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a3cab2a21744826b1ffe76cf076f6f4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0342488288879395, 'eval_runtime': 0.796, 'eval_samples_per_second': 21.356, 'eval_steps_per_second': 21.356, 'epoch': 12.94}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9828, 'learning_rate': 2.125e-05, 'epoch': 13.53}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbd2220158154ee78bbceea19a5255b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0955018997192383, 'eval_runtime': 1.2666, 'eval_samples_per_second': 13.422, 'eval_steps_per_second': 13.422, 'epoch': 13.53}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9814, 'learning_rate': 2e-05, 'epoch': 14.12}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04ea6741026b406bad7f64057fa5b1ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9588403701782227, 'eval_runtime': 0.6975, 'eval_samples_per_second': 24.374, 'eval_steps_per_second': 24.374, 'epoch': 14.12}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.951, 'learning_rate': 1.8750000000000002e-05, 'epoch': 14.71}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a37d7dd93c4410f83c5b451299f5535","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.066065788269043, 'eval_runtime': 0.6032, 'eval_samples_per_second': 28.183, 'eval_steps_per_second': 28.183, 'epoch': 14.71}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0126, 'learning_rate': 1.75e-05, 'epoch': 15.29}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36daa7b7f1ca479fbd2ef4d84fce77df","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.948521375656128, 'eval_runtime': 0.5946, 'eval_samples_per_second': 28.591, 'eval_steps_per_second': 28.591, 'epoch': 15.29}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9675, 'learning_rate': 1.6250000000000002e-05, 'epoch': 15.88}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cadebd39131b4ac094abada7e027bad8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9857310056686401, 'eval_runtime': 0.6068, 'eval_samples_per_second': 28.017, 'eval_steps_per_second': 28.017, 'epoch': 15.88}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9996, 'learning_rate': 1.5e-05, 'epoch': 16.47}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13d20a882167485aa774e42f6462d3f9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.942827820777893, 'eval_runtime': 0.9039, 'eval_samples_per_second': 18.807, 'eval_steps_per_second': 18.807, 'epoch': 16.47}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9634, 'learning_rate': 1.3750000000000002e-05, 'epoch': 17.06}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9000ac25d4a4359881e1a5b8ec0d1da","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9941967725753784, 'eval_runtime': 0.9006, 'eval_samples_per_second': 18.876, 'eval_steps_per_second': 18.876, 'epoch': 17.06}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9657, 'learning_rate': 1.25e-05, 'epoch': 17.65}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61191bf056804adeb920494b2538e12c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./pretrained-bert\\checkpoint-300\n","Configuration saved in ./pretrained-bert\\checkpoint-300\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9472496509552002, 'eval_runtime': 0.843, 'eval_samples_per_second': 20.167, 'eval_steps_per_second': 20.167, 'epoch': 17.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./pretrained-bert\\checkpoint-300\\pytorch_model.bin\n","Deleting older checkpoint [pretrained-bert\\checkpoint-200] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9365, 'learning_rate': 1.125e-05, 'epoch': 18.24}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7d7a1808a614fbc8f1b55bbabe9f98b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9396028518676758, 'eval_runtime': 0.7251, 'eval_samples_per_second': 23.446, 'eval_steps_per_second': 23.446, 'epoch': 18.24}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9487, 'learning_rate': 1e-05, 'epoch': 18.82}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecbfa1e723794742b27edf83fd876928","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9598592519760132, 'eval_runtime': 0.6008, 'eval_samples_per_second': 28.298, 'eval_steps_per_second': 28.298, 'epoch': 18.82}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9245, 'learning_rate': 8.75e-06, 'epoch': 19.41}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"765de6a1ee994656b3b3522cc70238c9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.03629994392395, 'eval_runtime': 0.5787, 'eval_samples_per_second': 29.376, 'eval_steps_per_second': 29.376, 'epoch': 19.41}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9294, 'learning_rate': 7.5e-06, 'epoch': 20.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd1ee78de3ab41afab0d1581e9199d60","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9858273267745972, 'eval_runtime': 0.5901, 'eval_samples_per_second': 28.811, 'eval_steps_per_second': 28.811, 'epoch': 20.0}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9591, 'learning_rate': 6.25e-06, 'epoch': 20.59}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8214590ca8144d93a8fd0e21f1ff62bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.99700927734375, 'eval_runtime': 0.6345, 'eval_samples_per_second': 26.791, 'eval_steps_per_second': 26.791, 'epoch': 20.59}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.8875, 'learning_rate': 5e-06, 'epoch': 21.18}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4aa622124e34b028a00679cf99077ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0407402515411377, 'eval_runtime': 0.5975, 'eval_samples_per_second': 28.451, 'eval_steps_per_second': 28.451, 'epoch': 21.18}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.951, 'learning_rate': 3.75e-06, 'epoch': 21.76}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"527dec5e1dc147a0889c66d056649015","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9535870552062988, 'eval_runtime': 0.5573, 'eval_samples_per_second': 30.505, 'eval_steps_per_second': 30.505, 'epoch': 21.76}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9231, 'learning_rate': 2.5e-06, 'epoch': 22.35}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ced64a9a4d94f9fb335f5605e3fda21","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9978704452514648, 'eval_runtime': 0.5954, 'eval_samples_per_second': 28.55, 'eval_steps_per_second': 28.55, 'epoch': 22.35}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.0096, 'learning_rate': 1.25e-06, 'epoch': 22.94}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"199c2dab45e54a76a5b29c6765bf8457","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.9650108814239502, 'eval_runtime': 0.6476, 'eval_samples_per_second': 26.252, 'eval_steps_per_second': 26.252, 'epoch': 22.94}\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: cluster_id, color, special_tokens_mask, okr_num. If cluster_id, color, special_tokens_mask, okr_num are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 17\n","  Batch size = 1\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.9332, 'learning_rate': 0.0, 'epoch': 23.53}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b53fc3e4a264b5381310513cbb711e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./pretrained-bert\\checkpoint-400\n","Configuration saved in ./pretrained-bert\\checkpoint-400\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.8822731971740723, 'eval_runtime': 0.7716, 'eval_samples_per_second': 22.033, 'eval_steps_per_second': 22.033, 'epoch': 23.53}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./pretrained-bert\\checkpoint-400\\pytorch_model.bin\n","Deleting older checkpoint [pretrained-bert\\checkpoint-300] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["{'train_runtime': 300.1643, 'train_samples_per_second': 5.33, 'train_steps_per_second': 1.333, 'train_loss': 2.3675238847732545, 'epoch': 23.53}\n"]},{"data":{"text/plain":["TrainOutput(global_step=400, training_loss=2.3675238847732545, metrics={'train_runtime': 300.1643, 'train_samples_per_second': 5.33, 'train_steps_per_second': 1.333, 'train_loss': 2.3675238847732545, 'epoch': 23.53})"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# load data\n","train_dataset = load_from_disk(f\"{file_path}/train\")\n","test_dataset = load_from_disk(f\"{file_path}/test\")\n","\n","# load tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained(model_path)\n","\n","model_config = BertConfig(max_position_embeddings=512)\n","model = BertForMaskedLM(config=model_config)\n","\n","# initialize the data collator, randomly masking 15% of the tokens for\n","# the Masked Language Modeling (MLM) prediction task\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=True,\n","    mlm_probability=0.15\n",")\n","\n","# Learning rate selected by running ./hp_search.py\n","# Save model after 400 steps\n","training_args = TrainingArguments(\n","    output_dir=model_path,\n","    evaluation_strategy=\"steps\",\n","    overwrite_output_dir=True,\n","    max_steps=400,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=4,\n","    learning_rate=5e-5,\n","    logging_steps=10,\n","    save_steps=100,       \n","    save_total_limit=1,\n","    seed=SEED\n",")\n","\n","# initialize the trainer and pass everything to it\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")\n","\n","# train the model\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["It seems like our model is fairly robust -- it has converged to a stable (low) error rate and performs similarly well with held-out validation data that it has never seen before."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1711897313317,"user":{"displayName":"Jon Clindaniel","userId":"17358510137887145828"},"user_tz":300},"id":"2fc2xoU4Hovy","outputId":"63f1b124-c319-40ac-fb66-f0ad19f1f694"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Collect training and Evaluation Loss\n","log = pd.DataFrame(trainer.state.log_history)\n","train_loss = log[['loss', 'step']].dropna().rename(columns={'loss': 'training_loss'})\n","eval_loss = log[['eval_loss', 'step']].dropna().rename(columns={'eval_loss': 'validation_loss'})\n","\n","# Plot them\n","ax = train_loss.plot(x='step')\n","eval_loss.plot(x='step', ax=ax)\n","ax.set_xlabel('Step')\n","ax.set_ylabel('Cross-Entropy Loss')\n","ax.legend(labels=['Training', 'Validation']);"]},{"cell_type":"markdown","metadata":{"id":"b_pM1Ez1vMHZ"},"source":["The model was saved at the last checkpoint (400 steps), so we can load and use it in `khipubert_analysis.ipynb` to interpret what it has learned about how cord colors were used in Inka khipus."]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPkYc5z75F1WFDDdkqNMgrf","gpuType":"T4","mount_file_id":"1c15TjGI5Goiv1QYfsaxUy6xzX7wltsoz","provenance":[{"file_id":"1f6k7Jlseas8RpKsUj2cq0eybZJ5PFZh5","timestamp":1689980095898},{"file_id":"1drzjiVkmeDkTU1PCq3gBcH_CcrnlgydK","timestamp":1689519581845}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00d3c09880db452fb741c24b77305b77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"037255961faa4b3e9f7fc93aea3241d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"087e2dda94ae48b5940fe1046788b93e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"096bac360d254ef19e0dd7b25dd23e48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ecff2dd44dc474d8b415ce4edf02de6","max":68,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d71f0e5d89a74949a396af67f4dd7b9d","value":68}},"09a1ef5b504f48c1a9764a5976e697d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e808be0cfa44d249c9d1252f9a33a85","placeholder":"","style":"IPY_MODEL_0d4c9a9cabe8452e9f34439fc01db253","value":" 5273/5273 [00:00&lt;00:00, 14230.11 examples/s]"}},"0d4c9a9cabe8452e9f34439fc01db253":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e4a243c0ffb4d6a8e0f2345a4ef2db1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee2e9be1159540579465684704237e97","IPY_MODEL_986dd0a366e34022a1aeea06a61fcf6b","IPY_MODEL_52a4e5f9973f418ba3f669b2ec7a33cf"],"layout":"IPY_MODEL_087e2dda94ae48b5940fe1046788b93e"}},"0ecff2dd44dc474d8b415ce4edf02de6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"117ab056d43e45aa839b38e4453274ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15ca1b1cdcd24efcae051bebebe3b2ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15f1dcce6b58451fa2d80931e4b49a73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17fb4b7c57324b09acbce35c5a735715":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21715587340b4c5fbb8b5cb2b9d3d664":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"227761f31b084d14bb6def78d797efd4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c8310205c6041b1b2ea9dad30e5d62f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e12cb0bfd3441ffad6a7da14df21393":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8e97e454384db4ba9a7c06073ca5c4","placeholder":"","style":"IPY_MODEL_f87bf027260d4cd2a53f5f49fbecf741","value":" 17/17 [00:01&lt;00:00, 13.55 examples/s]"}},"2f870e8cafe6498a86d89b99d3af956b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a35e7a662d364fa1abacc84bbe10a0cf","placeholder":"","style":"IPY_MODEL_88bc9b8b142f4343858e4087965aed63","value":" 1319/1319 [00:00&lt;00:00, 9960.04 examples/s]"}},"31db8f0749284e9c8f5745352474fc2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3313a12496d94fdaa8ce49c7d791edc8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34780ec893524d7ab805fe3dadc6b811":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40e2a77a2dc541808f6d2af22ff66ab7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"422f1045b6f24a92b7ba54a359b1e73c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46d100c32f06475babf5293ca3b22c6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efeab024444b4ca3aeab5b61d46cd83c","IPY_MODEL_096bac360d254ef19e0dd7b25dd23e48","IPY_MODEL_6307a900f2a24e8eb037cfa76b9854e9"],"layout":"IPY_MODEL_15f1dcce6b58451fa2d80931e4b49a73"}},"4e808be0cfa44d249c9d1252f9a33a85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52a4e5f9973f418ba3f669b2ec7a33cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dceec7de2d4241099e444c7d327dc834","placeholder":"","style":"IPY_MODEL_942a10847a2841d89e4ba0ca03ce3ee5","value":" 5273/5273 [00:00&lt;00:00, 8917.10 examples/s]"}},"52ee20b10eca4cfc8c837fdf22860b1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54fe9f1c84874a3391af0ff86277b2cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8865bbf1e492471381609b48b756a2fb","placeholder":"","style":"IPY_MODEL_21715587340b4c5fbb8b5cb2b9d3d664","value":"Grouping texts in chunks of 512: 100%"}},"5f3a6461685445bcbccb240ba3c0fab6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c2402cb5cdb40d0a2e3ed97194462fd","IPY_MODEL_aa37590628ec4bf9884cb1c1b451ea9d","IPY_MODEL_09a1ef5b504f48c1a9764a5976e697d3"],"layout":"IPY_MODEL_9a9cf7a1fe2742aa892c04aa352b28af"}},"610d9bd12012465eaea85ed9b410753d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a9775858d734fb79294c701d9230b44","placeholder":"","style":"IPY_MODEL_17fb4b7c57324b09acbce35c5a735715","value":" 1319/1319 [00:00&lt;00:00, 9448.84 examples/s]"}},"6307a900f2a24e8eb037cfa76b9854e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6c10aecea3c4a2a90760b3c8262727b","placeholder":"","style":"IPY_MODEL_037255961faa4b3e9f7fc93aea3241d9","value":" 68/68 [00:01&lt;00:00, 54.48 examples/s]"}},"682f0d7060a449dfbbee0705ff5e23bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54fe9f1c84874a3391af0ff86277b2cf","IPY_MODEL_f514f09c710041d49c47593f7075bb9a","IPY_MODEL_2f870e8cafe6498a86d89b99d3af956b"],"layout":"IPY_MODEL_2c8310205c6041b1b2ea9dad30e5d62f"}},"6c2402cb5cdb40d0a2e3ed97194462fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ca1b1cdcd24efcae051bebebe3b2ee","placeholder":"","style":"IPY_MODEL_e0f9c2ec412049f2a5acd275dcc05def","value":"Grouping texts in chunks of 512: 100%"}},"6c7dcd616828487a9ab4611e26389397":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"784aa071c99e4172a458ec1df4938721":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78739a07dd6e4f45898150c283a9a747":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c7dcd616828487a9ab4611e26389397","placeholder":"","style":"IPY_MODEL_e0f5e6c649a3439a83c6b334958c9518","value":"Map: 100%"}},"80c25465aeae42b19c33483bcdd90831":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8865bbf1e492471381609b48b756a2fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88bc9b8b142f4343858e4087965aed63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a9775858d734fb79294c701d9230b44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"928d4bdb9e474af6aede0b11e6ce8d24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7e07967d0244e229862ed986c9b74f9","max":1319,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5a89aaf36b54590a1b57957eaf7732e","value":1319}},"942a10847a2841d89e4ba0ca03ce3ee5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"986dd0a366e34022a1aeea06a61fcf6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3313a12496d94fdaa8ce49c7d791edc8","max":5273,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0fe3eab405a45c89c60396b12fff84e","value":5273}},"9a9cf7a1fe2742aa892c04aa352b28af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35e7a662d364fa1abacc84bbe10a0cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa37590628ec4bf9884cb1c1b451ea9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00d3c09880db452fb741c24b77305b77","max":5273,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31db8f0749284e9c8f5745352474fc2a","value":5273}},"b6c10aecea3c4a2a90760b3c8262727b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6fb78eb656a4969955496ab74a38459":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba8e97e454384db4ba9a7c06073ca5c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd0c148658eb46e9b7bf5b2e3a727cd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1c84d91af4b4aa0bff4950c7df0e6a9","max":17,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6fb78eb656a4969955496ab74a38459","value":17}},"bdf17793746049e58f4baeac1289f83e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9f84369cfd243efb2b891ce78878e37","IPY_MODEL_bd0c148658eb46e9b7bf5b2e3a727cd6","IPY_MODEL_2e12cb0bfd3441ffad6a7da14df21393"],"layout":"IPY_MODEL_40e2a77a2dc541808f6d2af22ff66ab7"}},"be110631983d4b29a0d41d6b307e7871":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7e07967d0244e229862ed986c9b74f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d71f0e5d89a74949a396af67f4dd7b9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dceec7de2d4241099e444c7d327dc834":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0f5e6c649a3439a83c6b334958c9518":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0f9c2ec412049f2a5acd275dcc05def":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1c84d91af4b4aa0bff4950c7df0e6a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e331243aab7c45d990873375bd2becd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78739a07dd6e4f45898150c283a9a747","IPY_MODEL_928d4bdb9e474af6aede0b11e6ce8d24","IPY_MODEL_610d9bd12012465eaea85ed9b410753d"],"layout":"IPY_MODEL_227761f31b084d14bb6def78d797efd4"}},"e4dde512a0ab40f7872c088d05398924":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5a89aaf36b54590a1b57957eaf7732e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9f84369cfd243efb2b891ce78878e37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34780ec893524d7ab805fe3dadc6b811","placeholder":"","style":"IPY_MODEL_e4dde512a0ab40f7872c088d05398924","value":"Saving the dataset (1/1 shards): 100%"}},"ee2e9be1159540579465684704237e97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80c25465aeae42b19c33483bcdd90831","placeholder":"","style":"IPY_MODEL_117ab056d43e45aa839b38e4453274ca","value":"Map: 100%"}},"efeab024444b4ca3aeab5b61d46cd83c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_422f1045b6f24a92b7ba54a359b1e73c","placeholder":"","style":"IPY_MODEL_be110631983d4b29a0d41d6b307e7871","value":"Saving the dataset (1/1 shards): 100%"}},"f0fe3eab405a45c89c60396b12fff84e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f514f09c710041d49c47593f7075bb9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52ee20b10eca4cfc8c837fdf22860b1e","max":1319,"min":0,"orientation":"horizontal","style":"IPY_MODEL_784aa071c99e4172a458ec1df4938721","value":1319}},"f87bf027260d4cd2a53f5f49fbecf741":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
